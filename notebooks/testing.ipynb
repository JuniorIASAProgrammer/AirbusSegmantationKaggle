{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "def mask_converter(values):\n",
    "    mask = np.zeros((768*768,), dtype=float)        #create empty one-dimentional vector with zeros\n",
    "    if isinstance(values, str):\n",
    "        values = values.strip().split()\n",
    "        start_points = values[0::2]               #separate values\n",
    "        lengths = values[1::2]\n",
    "        for st_p, l in zip(start_points, lengths):     #fill mask with ones according to the EncodedPixels colomn\n",
    "            st_p, l = int(st_p)-1, int(l)\n",
    "            ones = np.ones(l, dtype=int) \n",
    "            mask[int(st_p):int(st_p)+int(l)] = ones\n",
    "    return mask.reshape((768, 768, 1))\n",
    "\n",
    "\n",
    "# CNN\n",
    "# encoder\n",
    "def conv_block(inputs=None, n_filters=32, max_pooling=True):\n",
    "    conv = Conv2D(n_filters, kernel_size=3, \n",
    "                activation='relu', \n",
    "                padding='same', \n",
    "                kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    conv = Conv2D(n_filters, kernel_size=3, \n",
    "                activation='relu', \n",
    "                padding='same', \n",
    "                kernel_initializer='he_normal')(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(2)(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv          #save skip-connection for further usage in decoding\n",
    "    return next_layer, skip_connection\n",
    "\n",
    "\n",
    "# decoder\n",
    "def upsampling_block(previous_layer, prevoius_skip_layer, n_filters=32):\n",
    "    upsampling = Conv2DTranspose(n_filters,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=2,\n",
    "                                    padding='same')(previous_layer)\n",
    "    merge = concatenate([upsampling, prevoius_skip_layer])\n",
    "    conv = Conv2D(n_filters,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "# initializing U-net model\n",
    "def unet_model(input_size=(768,768,3), n_filters=32, n_classes=2):\n",
    "    inputs = Input(input_size)\n",
    "    # downsampling\n",
    "    c1, skip1 = conv_block(inputs, n_filters)\n",
    "    c2, skip2 = conv_block(c1, n_filters*2)\n",
    "    c3, skip3 = conv_block(c2, n_filters*4)\n",
    "    c4, skip4 = conv_block(c3, n_filters*8)\n",
    "    c5, _ = conv_block(c4, n_filters*16, max_pooling=False) \n",
    "\n",
    "    # uplampling\n",
    "    c6 = upsampling_block(c5, skip4, n_filters*8)\n",
    "    c7 = upsampling_block(c6, skip3, n_filters*4)\n",
    "    c8 = upsampling_block(c7, skip2, n_filters*2)\n",
    "    c9 = upsampling_block(c8, skip1, n_filters)\n",
    "\n",
    "    # output\n",
    "    c10 = Conv2D(n_classes, kernel_size=1, padding='same')(c9)\n",
    "    return Model(inputs=inputs, outputs=c10)\n",
    "\n",
    "\n",
    "# initializing dice metric\n",
    "def dice_coef(y_true, y_pred, smooth=1e-3):\n",
    "  intersection = K.sum(y_true * y_pred)\n",
    "  union = K.sum(y_true) + K.sum(y_pred)\n",
    "  #dice = K.mean((2. * intersection + smooth)/(union + smooth), axis=0)\n",
    "  return (2*float(intersection)+smooth)/(float(union)+smooth)\n",
    "\n",
    "\n",
    "def process_path(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [768,768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[[0, 0, 0],\n",
    "                [0, 1, 1],\n",
    "                [0, 1, 0]],\n",
    "            [[0, 0, 0],\n",
    "                [0, 1, 1],\n",
    "                [0, 1, 0]]])\n",
    "y = np.array([[0, 0, 0],\n",
    "                [1, 1, 1],\n",
    "                [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = X*y\n",
    "union = X+y\n",
    "intersection = intersection.sum()\n",
    "union = union.sum()\n",
    "print(intersection)\n",
    "print(union)\n",
    "print(2*intersection/union)\n",
    "print(dice_coef(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_SHIP_PATH = '../data/processed/train_ship_segmentations_grouped.csv'\n",
    "TRAIN_PICS_DIRECTORY = '../data/external/train_v2/'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "unet = unet_model()\n",
    "unet.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL\n",
    "labels_file = pd.read_csv(CSV_SHIP_PATH)\n",
    "images, labels = labels_file['ImageId'], labels_file['EncodedPixels'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [TRAIN_PICS_DIRECTORY+i for i in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.data.Dataset.list_files(image_list, shuffle=False)\n",
    "y = tf.data.Dataset.from_tensor_slices(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.map(process_path)\n",
    "y = y.map(mask_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip((X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "def mask_converter(values):\n",
    "    mask = np.zeros((768*768,), dtype=float)        #create empty one-dimentional vector with zeros\n",
    "    if isinstance(values, str):\n",
    "        values = values.strip().split()\n",
    "        start_points = values[0::2]               #separate values\n",
    "        lengths = values[1::2]\n",
    "        for st_p, l in zip(start_points, lengths):     #fill mask with ones according to the EncodedPixels colomn\n",
    "            st_p, l = int(st_p)-1, int(l)\n",
    "            ones = np.ones(l, dtype=int) \n",
    "            mask[int(st_p):int(st_p)+int(l)] = ones\n",
    "    return mask.reshape((768, 768,1))\n",
    "\n",
    "\n",
    "# CNN\n",
    "# encoder\n",
    "def conv_block(inputs=None, n_filters=32, max_pooling=True):\n",
    "    conv = Conv2D(n_filters, kernel_size=3, \n",
    "                activation='relu', \n",
    "                padding='same', \n",
    "                kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    conv = Conv2D(n_filters, kernel_size=3, \n",
    "                activation='relu', \n",
    "                padding='same', \n",
    "                kernel_initializer='he_normal')(conv)\n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(2)(conv)\n",
    "    else:\n",
    "        next_layer = conv\n",
    "    skip_connection = conv          #save skip-connection for further usage in decoding\n",
    "    return next_layer, skip_connection\n",
    "\n",
    "\n",
    "# decoder\n",
    "def upsampling_block(previous_layer, prevoius_skip_layer, n_filters=32):\n",
    "    upsampling = Conv2DTranspose(n_filters,\n",
    "                                    kernel_size=3,\n",
    "                                    strides=2,\n",
    "                                    padding='same')(previous_layer)\n",
    "    merge = concatenate([upsampling, prevoius_skip_layer])\n",
    "    conv = Conv2D(n_filters,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(merge)\n",
    "    conv = Conv2D(n_filters,\n",
    "                 kernel_size=3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "# initializing U-net model\n",
    "def unet_model(input_size=(768,768,3), n_filters=32, n_classes=2):\n",
    "    inputs = Input(input_size)\n",
    "    # downsampling\n",
    "    c1, skip1 = conv_block(inputs, n_filters)\n",
    "    c2, skip2 = conv_block(c1, n_filters*2)\n",
    "    c3, skip3 = conv_block(c2, n_filters*4)\n",
    "    c4, skip4 = conv_block(c3, n_filters*8)\n",
    "    c5, _ = conv_block(c4, n_filters*16, max_pooling=False) \n",
    "\n",
    "    # uplampling\n",
    "    c6 = upsampling_block(c5, skip4, n_filters*8)\n",
    "    c7 = upsampling_block(c6, skip3, n_filters*4)\n",
    "    c8 = upsampling_block(c7, skip2, n_filters*2)\n",
    "    c9 = upsampling_block(c8, skip1, n_filters)\n",
    "\n",
    "    # output\n",
    "    c10 = Conv2D(n_classes, kernel_size=1, padding='same')(c9)\n",
    "    return Model(inputs=inputs, outputs=c10)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def process_path(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "  # Convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.io.decode_jpeg(img, channels=3)\n",
    "  # Resize the image to the desired size\n",
    "  return tf.image.resize(img, [768,768,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants initialization\n",
    "CSV_SHIP_PATH = '../data/processed/train_ship_segmentations_grouped.csv'\n",
    "TRAIN_PICS_DIRECTORY = '../data/external/train_v2/'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Create u-net\n",
    "unet = unet_model()\n",
    "unet.compile(optimizer='adam',\n",
    "              loss=dice_coef_loss,\n",
    "              metrics=[dice_coef])\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETL\n",
    "labels_file = pd.read_csv(CSV_SHIP_PATH)            # Read preprocessed csv file\n",
    "images, labels = labels_file['ImageId'], labels_file['EncodedPixels'].to_numpy()            # Extract labels and images with ships\n",
    "image_list = [TRAIN_PICS_DIRECTORY+i for i in images]           # Create list of images   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.data.Dataset.list_files(image_list, shuffle=False)           # Convert data into tf.Dataset\n",
    "y = tf.data.Dataset.from_tensor_slices(labels)\n",
    "X = X.map(process_path)             \n",
    "y = y.map(mask_converter)           # Convert start points and run length into mask\n",
    "train_dataset = tf.data.Dataset.zip((X, y))             # Merge images and masks together\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)             # Set batch size\n",
    "model_history = unet.fit(train_dataset, epochs=EPOCHS)          # Fit model\n",
    "unet.save('01_unet_model')             # Save model to use    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62e30423145a93faf211ab9b704908ae7403ade2b25694c7d14278daea2f18c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
